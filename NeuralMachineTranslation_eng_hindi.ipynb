{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TphUnHWf_52Y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import nltk.translate.bleu_score as bleu\n",
        "import random\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuPwOyols0bi",
        "outputId": "c5814590-e52d-41c5-878a-6ca8ccc7857c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "X4Opm0xU_7OX",
        "outputId": "b2e5e6f7-7321-45d8-fb7d-bf00a7aae7cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                   english_sentence  \\\n",
              "0           0  politicians do not have permission to do what ...   \n",
              "1           1         I'd like to tell you about one such child,   \n",
              "2           2  This percentage is even greater than the perce...   \n",
              "3           3  what we really mean is that they're bad at not...   \n",
              "4           4  .The ending portion of these Vedas is called U...   \n",
              "\n",
              "                                      hindi_sentence  \n",
              "0  राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
              "1  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
              "2   यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।  \n",
              "3     हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
              "4        इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e004cb55-216d-4d79-be3a-2663d799f0b7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>politicians do not have permission to do what ...</td>\n",
              "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>I'd like to tell you about one such child,</td>\n",
              "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>This percentage is even greater than the perce...</td>\n",
              "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>what we really mean is that they're bad at not...</td>\n",
              "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>.The ending portion of these Vedas is called U...</td>\n",
              "      <td>इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e004cb55-216d-4d79-be3a-2663d799f0b7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e004cb55-216d-4d79-be3a-2663d799f0b7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e004cb55-216d-4d79-be3a-2663d799f0b7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "eng_hin=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/self learning/newdata.csv')\n",
        "eng_hin.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yQUqA6g_8lh",
        "outputId": "7589334c-fce4-49a1-e68f-5b11d94439e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "eng_hin.dropna(inplace=True)\n",
        "eng_hin=eng_hin[:50000]\n",
        "eng_hin.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
        "eng_hin.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlhv9yF1AIBf"
      },
      "outputs": [],
      "source": [
        "exclude = set(string.punctuation) # Set of all special characters\n",
        "remove_digits = str.maketrans('', '', string.digits) # Set of all digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeQ2I1iDAJ5o"
      },
      "outputs": [],
      "source": [
        "def preprocess(text):\n",
        "    '''Function to preprocess English sentence'''\n",
        "    text = text.lower() # lower casing\n",
        "    text = re.sub(\"'\", '', text) # remove the quotation marks if any\n",
        "    text = ''.join(ch for ch in text if ch not in exclude)\n",
        "    text = text.translate(remove_digits) # remove the digits\n",
        "    text = text.strip()\n",
        "    text = re.sub(\" +\", \" \", text) # remove extra spaces\n",
        "    text = '<start> ' + text + ' <end>'\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQcdfXMDALjr"
      },
      "outputs": [],
      "source": [
        "def preprocess_hin(text):\n",
        "    '''Function to preprocess Marathi sentence'''\n",
        "    text = re.sub(\"'\", '', text) # remove the quotation marks if any\n",
        "    text = ''.join(ch for ch in text if ch not in exclude)\n",
        "    text = re.sub(\"[२३०८१५७९४६]\", \"\", text) # remove the digits\n",
        "    text = text.strip()\n",
        "    text = re.sub(\" +\", \" \", text) # remove extra spaces\n",
        "    text = '<start> ' + text + ' <end>'\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uYYoa6mfAc0Q",
        "outputId": "380ec217-d281-4389-8b4d-77d2df51892f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             english  \\\n",
              "0  <start> politicians do not have permission to ...   \n",
              "1  <start> id like to tell you about one such chi...   \n",
              "2  <start> this percentage is even greater than t...   \n",
              "3  <start> what we really mean is that theyre bad...   \n",
              "4  <start> the ending portion of these vedas is c...   \n",
              "\n",
              "                                               hindi  \n",
              "0  <start> राजनीतिज्ञों के पास जो कार्य करना चाहि...  \n",
              "1  <start> मई आपको ऐसे ही एक बच्चे के बारे में बत...  \n",
              "2  <start> यह प्रतिशत भारत में हिन्दुओं प्रतिशत स...  \n",
              "3  <start> हम ये नहीं कहना चाहते कि वो ध्यान नहीं...  \n",
              "4  <start> इन्हीं वेदों का अंतिम भाग उपनिषद कहलात...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41dd5df6-8746-4a7e-8444-740e61506706\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>hindi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;start&gt; politicians do not have permission to ...</td>\n",
              "      <td>&lt;start&gt; राजनीतिज्ञों के पास जो कार्य करना चाहि...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;start&gt; id like to tell you about one such chi...</td>\n",
              "      <td>&lt;start&gt; मई आपको ऐसे ही एक बच्चे के बारे में बत...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;start&gt; this percentage is even greater than t...</td>\n",
              "      <td>&lt;start&gt; यह प्रतिशत भारत में हिन्दुओं प्रतिशत स...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;start&gt; what we really mean is that theyre bad...</td>\n",
              "      <td>&lt;start&gt; हम ये नहीं कहना चाहते कि वो ध्यान नहीं...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;start&gt; the ending portion of these vedas is c...</td>\n",
              "      <td>&lt;start&gt; इन्हीं वेदों का अंतिम भाग उपनिषद कहलात...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41dd5df6-8746-4a7e-8444-740e61506706')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-41dd5df6-8746-4a7e-8444-740e61506706 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-41dd5df6-8746-4a7e-8444-740e61506706');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "eng_hin['english_sentence'] = eng_hin['english_sentence'].apply(preprocess)\n",
        "eng_hin['hindi_sentence'] = eng_hin['hindi_sentence'].apply(preprocess_hin)\n",
        "\n",
        "eng_hin.rename(columns={\"english_sentence\": \"english\", \"hindi_sentence\": \"hindi\"},inplace=True)\n",
        "\n",
        "eng_hin.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zNS9JknEWfa"
      },
      "outputs": [],
      "source": [
        "def tokenize(lang):\n",
        "\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,padding='post',maxlen=20,dtype='int32')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jQkH882Fs9x"
      },
      "outputs": [],
      "source": [
        "def load_dataset():\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(eng_hin['english'].values)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(eng_hin['hindi'].values)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-Wg24AOFO9s"
      },
      "outputs": [],
      "source": [
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUvO_uSiGCLC"
      },
      "outputs": [],
      "source": [
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G9J9aanGEnY",
        "outputId": "9133ab30-7119-45ac-b416-4776d9aa271a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40000 40000 10000 10000\n"
          ]
        }
      ],
      "source": [
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9oyMQjLGZ4x"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "\n",
        "vocab_inp_size =len(inp_lang.word_index.keys())\n",
        "vocab_tar_size =len(targ_lang.word_index.keys())\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNco5Wlot2Gn",
        "outputId": "c025292c-0580-4a60-c837-84fcdc689f21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-10 18:23:27--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-04-10 18:23:27--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-04-10 18:23:28--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  4.92MB/s    in 2m 42s  \n",
            "\n",
            "2022-04-10 18:26:10 (5.09 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip glove*.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnuegR_-umkV",
        "outputId": "da96b94d-0002-42a5-91d0-85e519da67d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jx3kIxcVumnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKD-3jidQtND"
      },
      "outputs": [],
      "source": [
        "embeddings_index = dict()\n",
        "f = open('glove.6B.300d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_inp_size+1, 300))\n",
        "for word, i in inp_lang.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_-Bj6ENHE4I"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, name=\"embedding_layer_encoder\",trainable=False)\n",
        "        self.gru = tf.keras.layers.GRU(units, return_sequences=True, return_state=True, recurrent_activation='sigmoid', recurrent_initializer='glorot_uniform')\n",
        "        \n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state = hidden)\n",
        "        return output, state\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afDryQ94HdKt"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(units, return_sequences=True, return_state=True, recurrent_activation='sigmoid', recurrent_initializer='glorot_uniform')\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "                # used for attention\n",
        "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "\n",
        "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "        \n",
        "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
        "        \n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        \n",
        "        context_vector = attention_weights * enc_output\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        \n",
        "        x = self.embedding(x)\n",
        "        \n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        \n",
        "        output, state = self.gru(x)\n",
        "        \n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        \n",
        "        x = self.fc(output)\n",
        "        \n",
        "        return x, state, attention_weights\n",
        "        \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.dec_units))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oGe0qnwHyA5"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "encoder = Encoder(vocab_inp_size+1, 300, units, BATCH_SIZE)\n",
        "decoder = Decoder(vocab_tar_size+1, embedding_dim, units, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hV6fzW6vQzXd"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
        "                                                            reduction='none')\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3p3etBjuQ2M6"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xf-qboRWQ4nC"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "    encoder.get_layer('embedding_layer_encoder').set_weights([embedding_matrix])\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNTA90Y5UfeG",
        "outputId": "4f5fcd9f-d43e-46ba-b2e8-52e7e3e98ebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 6.7095\n",
            "Epoch 1 Batch 100 Loss 5.3537\n",
            "Epoch 1 Batch 200 Loss 4.9323\n",
            "Epoch 1 Batch 300 Loss 4.4431\n",
            "Epoch 1 Batch 400 Loss 4.2952\n",
            "Epoch 1 Batch 500 Loss 4.6263\n",
            "Epoch 1 Batch 600 Loss 3.9273\n",
            "Epoch 1 Loss 4.6485\n",
            "Time taken for 1 epoch 482.36 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 4.0598\n",
            "Epoch 2 Batch 100 Loss 3.9854\n",
            "Epoch 2 Batch 200 Loss 4.1363\n",
            "Epoch 2 Batch 300 Loss 4.1077\n",
            "Epoch 2 Batch 400 Loss 3.6295\n",
            "Epoch 2 Batch 500 Loss 3.9415\n",
            "Epoch 2 Batch 600 Loss 3.4059\n",
            "Epoch 2 Loss 3.9116\n",
            "Time taken for 1 epoch 450.81 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 3.4557\n",
            "Epoch 3 Batch 100 Loss 3.0616\n",
            "Epoch 3 Batch 200 Loss 3.2556\n",
            "Epoch 3 Batch 300 Loss 3.3500\n",
            "Epoch 3 Batch 400 Loss 3.0731\n",
            "Epoch 3 Batch 500 Loss 3.2402\n",
            "Epoch 3 Batch 600 Loss 3.2850\n",
            "Epoch 3 Loss 3.3063\n",
            "Time taken for 1 epoch 448.54 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 2.8819\n",
            "Epoch 4 Batch 100 Loss 2.5570\n",
            "Epoch 4 Batch 200 Loss 2.7267\n",
            "Epoch 4 Batch 300 Loss 2.6751\n",
            "Epoch 4 Batch 400 Loss 2.7784\n",
            "Epoch 4 Batch 500 Loss 2.8601\n",
            "Epoch 4 Batch 600 Loss 2.5953\n",
            "Epoch 4 Loss 2.6980\n",
            "Time taken for 1 epoch 451.38 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.9803\n",
            "Epoch 5 Batch 100 Loss 1.9849\n",
            "Epoch 5 Batch 200 Loss 2.2787\n",
            "Epoch 5 Batch 300 Loss 1.9867\n",
            "Epoch 5 Batch 400 Loss 2.4898\n",
            "Epoch 5 Batch 500 Loss 2.2016\n",
            "Epoch 5 Batch 600 Loss 2.0494\n",
            "Epoch 5 Loss 2.1048\n",
            "Time taken for 1 epoch 449.29 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 1.5166\n",
            "Epoch 6 Batch 100 Loss 1.5775\n",
            "Epoch 6 Batch 200 Loss 1.6468\n",
            "Epoch 6 Batch 300 Loss 1.6261\n",
            "Epoch 6 Batch 400 Loss 1.6837\n",
            "Epoch 6 Batch 500 Loss 1.8861\n",
            "Epoch 6 Batch 600 Loss 1.7459\n",
            "Epoch 6 Loss 1.6512\n",
            "Time taken for 1 epoch 449.65 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 1.1490\n",
            "Epoch 7 Batch 100 Loss 1.3568\n",
            "Epoch 7 Batch 200 Loss 1.2994\n",
            "Epoch 7 Batch 300 Loss 1.2427\n",
            "Epoch 7 Batch 400 Loss 1.2789\n",
            "Epoch 7 Batch 500 Loss 1.2163\n",
            "Epoch 7 Batch 600 Loss 1.5837\n",
            "Epoch 7 Loss 1.3313\n",
            "Time taken for 1 epoch 445.50 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 1.1077\n",
            "Epoch 8 Batch 100 Loss 0.9336\n",
            "Epoch 8 Batch 200 Loss 1.0626\n",
            "Epoch 8 Batch 300 Loss 1.1606\n",
            "Epoch 8 Batch 400 Loss 1.2199\n",
            "Epoch 8 Batch 500 Loss 0.9755\n",
            "Epoch 8 Batch 600 Loss 1.1626\n",
            "Epoch 8 Loss 1.0610\n",
            "Time taken for 1 epoch 453.06 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.7264\n",
            "Epoch 9 Batch 100 Loss 0.7850\n",
            "Epoch 9 Batch 200 Loss 0.8043\n",
            "Epoch 9 Batch 300 Loss 0.9254\n",
            "Epoch 9 Batch 400 Loss 0.7743\n",
            "Epoch 9 Batch 500 Loss 0.8959\n",
            "Epoch 9 Batch 600 Loss 0.8435\n",
            "Epoch 9 Loss 0.8308\n",
            "Time taken for 1 epoch 447.97 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.5791\n",
            "Epoch 10 Batch 100 Loss 0.6540\n",
            "Epoch 10 Batch 200 Loss 0.5731\n",
            "Epoch 10 Batch 300 Loss 0.5391\n",
            "Epoch 10 Batch 400 Loss 0.5772\n",
            "Epoch 10 Batch 500 Loss 0.8221\n",
            "Epoch 10 Batch 600 Loss 0.6523\n",
            "Epoch 10 Loss 0.6418\n",
            "Time taken for 1 epoch 451.95 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss 0.4048\n",
            "Epoch 11 Batch 100 Loss 0.4212\n",
            "Epoch 11 Batch 200 Loss 0.4863\n",
            "Epoch 11 Batch 300 Loss 0.4225\n",
            "Epoch 11 Batch 400 Loss 0.5925\n",
            "Epoch 11 Batch 500 Loss 0.4928\n",
            "Epoch 11 Batch 600 Loss 0.5682\n",
            "Epoch 11 Loss 0.4901\n",
            "Time taken for 1 epoch 443.71 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss 0.3310\n",
            "Epoch 12 Batch 100 Loss 0.3251\n",
            "Epoch 12 Batch 200 Loss 0.4356\n",
            "Epoch 12 Batch 300 Loss 0.4045\n",
            "Epoch 12 Batch 400 Loss 0.3545\n",
            "Epoch 12 Batch 500 Loss 0.3866\n",
            "Epoch 12 Batch 600 Loss 0.3803\n",
            "Epoch 12 Loss 0.3704\n",
            "Time taken for 1 epoch 450.55 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss 0.2337\n",
            "Epoch 13 Batch 100 Loss 0.2528\n",
            "Epoch 13 Batch 200 Loss 0.2823\n",
            "Epoch 13 Batch 300 Loss 0.2745\n",
            "Epoch 13 Batch 400 Loss 0.3161\n",
            "Epoch 13 Batch 500 Loss 0.3179\n",
            "Epoch 13 Batch 600 Loss 0.3085\n",
            "Epoch 13 Loss 0.2859\n",
            "Time taken for 1 epoch 447.43 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss 0.1994\n",
            "Epoch 14 Batch 100 Loss 0.2114\n",
            "Epoch 14 Batch 200 Loss 0.1813\n",
            "Epoch 14 Batch 300 Loss 0.2278\n",
            "Epoch 14 Batch 400 Loss 0.2229\n",
            "Epoch 14 Batch 500 Loss 0.2435\n",
            "Epoch 14 Batch 600 Loss 0.2043\n",
            "Epoch 14 Loss 0.2219\n",
            "Time taken for 1 epoch 451.26 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss 0.1532\n",
            "Epoch 15 Batch 100 Loss 0.1900\n",
            "Epoch 15 Batch 200 Loss 0.1556\n",
            "Epoch 15 Batch 300 Loss 0.1743\n",
            "Epoch 15 Batch 400 Loss 0.2144\n",
            "Epoch 15 Batch 500 Loss 0.2381\n",
            "Epoch 15 Batch 600 Loss 0.2152\n",
            "Epoch 15 Loss 0.1802\n",
            "Time taken for 1 epoch 444.63 sec\n",
            "\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 15\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print(f'Epoch {epoch+1} Batch {batch} Loss {batch_loss.numpy():.4f}')\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "  print(f'Epoch {epoch+1} Loss {total_loss/steps_per_epoch:.4f}')\n",
        "  print(f'Time taken for 1 epoch {time.time()-start:.2f} sec\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQLadYyExzp3",
        "outputId": "494fbf81-d32c-44d7-db5e-6bdc539e780b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 Batch 0 Loss 0.1210\n",
            "Epoch 16 Batch 100 Loss 0.1834\n",
            "Epoch 16 Batch 200 Loss 0.1637\n",
            "Epoch 16 Batch 300 Loss 0.1369\n",
            "Epoch 16 Batch 400 Loss 0.1345\n",
            "Epoch 16 Batch 500 Loss 0.1712\n",
            "Epoch 16 Batch 600 Loss 0.1712\n",
            "Epoch 16 Loss 0.1564\n",
            "Time taken for 1 epoch 447.38 sec\n",
            "\n",
            "Epoch 17 Batch 0 Loss 0.1598\n",
            "Epoch 17 Batch 100 Loss 0.1284\n",
            "Epoch 17 Batch 200 Loss 0.1760\n",
            "Epoch 17 Batch 300 Loss 0.1783\n",
            "Epoch 17 Batch 400 Loss 0.1697\n",
            "Epoch 17 Batch 500 Loss 0.1366\n",
            "Epoch 17 Batch 600 Loss 0.1410\n",
            "Epoch 17 Loss 0.1449\n",
            "Time taken for 1 epoch 445.41 sec\n",
            "\n",
            "Epoch 18 Batch 0 Loss 0.1139\n",
            "Epoch 18 Batch 100 Loss 0.1127\n",
            "Epoch 18 Batch 200 Loss 0.1304\n",
            "Epoch 18 Batch 300 Loss 0.1009\n",
            "Epoch 18 Batch 400 Loss 0.1171\n",
            "Epoch 18 Batch 500 Loss 0.1297\n",
            "Epoch 18 Batch 600 Loss 0.1686\n",
            "Epoch 18 Loss 0.1218\n",
            "Time taken for 1 epoch 449.47 sec\n",
            "\n",
            "Epoch 19 Batch 0 Loss 0.1292\n",
            "Epoch 19 Batch 100 Loss 0.0871\n",
            "Epoch 19 Batch 200 Loss 0.1097\n",
            "Epoch 19 Batch 300 Loss 0.0968\n",
            "Epoch 19 Batch 400 Loss 0.1216\n",
            "Epoch 19 Batch 500 Loss 0.1386\n",
            "Epoch 19 Batch 600 Loss 0.1282\n",
            "Epoch 19 Loss 0.1127\n",
            "Time taken for 1 epoch 442.75 sec\n",
            "\n",
            "Epoch 20 Batch 0 Loss 0.1078\n",
            "Epoch 20 Batch 100 Loss 0.1127\n",
            "Epoch 20 Batch 200 Loss 0.1540\n",
            "Epoch 20 Batch 300 Loss 0.0853\n",
            "Epoch 20 Batch 400 Loss 0.1076\n",
            "Epoch 20 Batch 500 Loss 0.1223\n",
            "Epoch 20 Batch 600 Loss 0.1520\n",
            "Epoch 20 Loss 0.1107\n",
            "Time taken for 1 epoch 448.70 sec\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS,20):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print(f'Epoch {epoch+1} Batch {batch} Loss {batch_loss.numpy():.4f}')\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "  print(f'Epoch {epoch+1} Loss {total_loss/steps_per_epoch:.4f}')\n",
        "  print(f'Time taken for 1 epoch {time.time()-start:.2f} sec\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0sehhJFjZhE"
      },
      "outputs": [],
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],maxlen=20, padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result,attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result,attention_plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9pfZPH2Rl2o",
        "outputId": "7a3e57fe-318c-46e5-9fb4-938ea5a95128"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input sentence in english :  please ensure that you use the appropriate form \n",
            "Predicted sentence in hindi :  कृपया यह सुनिश्चित कर लें कि आप सही फॉर्म का प्रयोग कर रहें हैं <end> \n"
          ]
        }
      ],
      "source": [
        "input_sentence= 'please ensure that you use the appropriate form '\n",
        "print('Input sentence in english : ',input_sentence)\n",
        "predicted_output,attention_plot=evaluate(input_sentence)\n",
        "print('Predicted sentence in hindi : ',predicted_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4z2NmL-vTCDr",
        "outputId": "8933f47c-9eff-49c9-8af8-777f9d8d7424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input sentence in english :  and do something with it to change the world \n",
            "Predicted sentence in hindi :  और इस दुनिया को बेहतर बनाने के लिये कुछ करेंगे । <end> \n"
          ]
        }
      ],
      "source": [
        "input_sentence='and do something with it to change the world '\n",
        "print('Input sentence in english : ',input_sentence)\n",
        "predicted_output,attention_plot=evaluate(input_sentence)\n",
        "print('Predicted sentence in hindi : ',predicted_output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Tc3yTMueRriR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KPGMBBmzR-Cy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "NeuralMachineTranslation_eng_hindi.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}